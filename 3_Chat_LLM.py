import streamlit as st
import os
from openai import OpenAI

# carrega chave
api_key = os.getenv("OPENAI_API_KEY")
client  = OpenAI(api_key=api_key)

st.set_page_config(page_title="Chat LLM", layout="wide")
st.header("ğŸ’¬ Perguntas e Respostas com LLM")

if "history" not in st.session_state:
    # vocÃª pode inserir aqui uma mensagem de sistema:
    st.session_state.history = [
        {"role": "system", "content": "Por enquanto vocÃª Ã© livre para responder."}
    ]

# entrada do usuÃ¡rio
query = st.text_input("Digite sua pergunta sobre os dados ou prediÃ§Ãµes")
if st.button("Enviar") and query:
    st.session_state.history.append({"role": "user", "content": query})

    with st.spinner("Pensandoâ€¦"):
        # use o namespace chat.completions.create
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=st.session_state.history
        )

    # agora vocÃª tem .choices
    content = response.choices[0].message.content
    st.session_state.history.append({"role": "assistant", "content": content})

# exibiÃ§Ã£o do histÃ³rico
from streamlit_chat import message
for msg in st.session_state.history:
    is_user = msg["role"] == "user"
    message(msg["content"], is_user=is_user)
