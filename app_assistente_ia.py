# app_assistente_ia.py

import streamlit as st
import os
# from openai import OpenAI   

def render():
    """
    FunÃ§Ã£o que desenha todo o conteÃºdo da Aba "Assistente IA".
    """
    if "history" not in st.session_state:
        st.session_state.history = []

    st.markdown("### ğŸ’¬ Assistente IA para IncÃªndios Florestais")

    # Caixa de texto para perguntar
    pergunta = st.text_input("FaÃ§a uma pergunta sobre os dados ou prediÃ§Ãµes")
    if st.button("Enviar") and pergunta:
        st.session_state.history.append({"role": "user", "content": pergunta})
        with st.spinner("Pensandoâ€¦"):
            # Exemplo de integraÃ§Ã£o com OpenAI (descomente e ajuste conforme sua API Key):
            # client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            # resposta = client.responses.create(
            #     model="gpt-4o-mini",
            #     instructions="VocÃª Ã© um assistente especializado em risco de incÃªndios florestais.",
            #     input=st.session_state.history
            # )
            # content = resposta.choices[0].message.content

            # Por enquanto, placeholder:
            content = "Estamos em manutenÃ§Ã£o"

        st.session_state.history.append({"role": "assistant", "content": content})

    # Exibe histÃ³rico de chat
    for chat in st.session_state.history:
        if chat["role"] == "user":
            st.markdown(f"**VocÃª:** {chat['content']}")
        else:
            st.markdown(f"**Assistente:** {chat['content']}")

    st.markdown("---")
    st.markdown(
        """
        **Como usar:**  
        - Pergunte algo como: â€œQual o risco previsto para MT hoje?â€  
        - Pergunte dados descritivos: â€œQuantos focos teve CÃ¡ceres no Ãºltimo mÃªs?â€  
        - Pergunte sobre o modelo preditivo: â€œComo a umidade afeta o risco?â€  

        """
    )
